{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN(FuncAPI).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVFTN0PgmRH/RLKYSL6vXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkeshun/til/blob/master/CNN(FuncAPI).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskZ4BWn4xua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "86041a5a-5b69-4101-e837-78b0f31b5e88"
      },
      "source": [
        "%%bash \n",
        "echo \"[CPU]\"; ls cpu\n",
        "echo; echo \"[Memory]\"; free -h\n",
        "echo; echo \"[Disk]\"; df -h /\n",
        "echo; echo \"[GPU]\" ; nvidia-smi\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CPU]\n",
            "\n",
            "[Memory]\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        560M         10G        900K        2.0G         11G\n",
            "Swap:            0B          0B          0B\n",
            "\n",
            "[Disk]\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay          69G   32G   34G  49% /\n",
            "\n",
            "[GPU]\n",
            "Tue Mar  3 14:55:11 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'cpu': No such file or directory\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFx4QACe5L0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47a5442b-c572-4eb6-8353-69b47c5866aa"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKkjf46S6b31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7fe364e-b971-458a-a108-59d0ae336cf5"
      },
      "source": [
        "%matplotlib\n",
        "import numpy as np\n",
        "from PIL import Image #画像処理ライブラリPillowのImageクラスをインポート\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist #kerasに内蔵されたMNISTを使う"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using matplotlib backend: agg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ5laAsS5QN4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "b73d9970-c507-4a05-9bff-7e7a04402258"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Reshape\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "#dataのロード\n",
        "(x_train, y_train) , (x_test,y_test) = mnist.load_data()\n",
        "#detaの1次元化\n",
        "num_train_data = x_train.shape[0]\n",
        "num_test_data  = x_test.shape[0]\n",
        "num_flatten_data = x_train.shape[1] * x_train.shape[2]\n",
        "#x_train = x_train.reshape(num_train_data,num_flatten_data)\n",
        "#x_test  = x_test.reshape(num_test_data, num_flatten_data)\n",
        "\n",
        "#0~1の範囲に収まるようにする\n",
        "num_gray_scale_max = 255\n",
        "x_train = x_train.astype('float32') / num_gray_scale_max\n",
        "x_test  = x_test.astype('float32')  / num_gray_scale_max\n",
        " \n",
        "#one-hot 第一パラメータに指定した変数を第二パラメータで指定した次元数でone-hotベクトルで変換できる\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test,num_classes)\n",
        "#モデル定義(Functionl)\n",
        "\"\"\"\n",
        "Functional APIでは呼び出す関数やクラスの末尾にテンソルをつけ，\n",
        "層の演算を適用して結果としてテンソル変数を返す\n",
        "\"\"\"\n",
        "input_shape = (28,28)\n",
        "#この下２つを使うときはデータをreshapeで一列にしない\n",
        "inputs = Input(shape=input_shape)#最初は28*28じゃダメ,エラー：Input 0 of layer conv2d_1 is incompatible with the layerが出る\n",
        "hidden = Reshape((28,28,1), input_shape = (28,28))(inputs)\n",
        "\n",
        "x = Conv2D(32,kernel_size=(3,3), activation='relu') (hidden)\n",
        "x = Conv2D(64,(3,3),activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(2,2)) (x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSk5sTdSEXQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "174dd301-31f8-4448-85cb-7cae4f51f367"
      },
      "source": [
        "#訓練開始\n",
        "batch_size = 128\n",
        "epochs = 1000\n",
        "history = model.fit(x_train, y_train,#訓練データと正解データ\n",
        "                    batch_size = batch_size, #バッチサイズ\n",
        "                    epochs=epochs,#エポック数\n",
        "                    verbose=1,#訓練の進行度合いを表示\n",
        "                    validation_data=(x_test, y_test)) #テスト"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "60000/60000 [==============================] - 14s 240us/sample - loss: 2.2625 - accuracy: 0.1535 - val_loss: 2.1947 - val_accuracy: 0.3218\n",
            "Epoch 2/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 2.1649 - accuracy: 0.2744 - val_loss: 2.0780 - val_accuracy: 0.5471\n",
            "Epoch 3/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 2.0473 - accuracy: 0.3843 - val_loss: 1.9273 - val_accuracy: 0.6582\n",
            "Epoch 4/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 1.8951 - accuracy: 0.4757 - val_loss: 1.7388 - val_accuracy: 0.7216\n",
            "Epoch 5/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 1.7202 - accuracy: 0.5468 - val_loss: 1.5273 - val_accuracy: 0.7611\n",
            "Epoch 6/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 1.5380 - accuracy: 0.5993 - val_loss: 1.3154 - val_accuracy: 0.7869\n",
            "Epoch 7/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 1.3684 - accuracy: 0.6363 - val_loss: 1.1255 - val_accuracy: 0.8023\n",
            "Epoch 8/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 1.2233 - accuracy: 0.6625 - val_loss: 0.9718 - val_accuracy: 0.8147\n",
            "Epoch 9/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 1.1102 - accuracy: 0.6846 - val_loss: 0.8539 - val_accuracy: 0.8248\n",
            "Epoch 10/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 1.0143 - accuracy: 0.7067 - val_loss: 0.7627 - val_accuracy: 0.8339\n",
            "Epoch 11/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.9451 - accuracy: 0.7204 - val_loss: 0.6938 - val_accuracy: 0.8414\n",
            "Epoch 12/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.8893 - accuracy: 0.7334 - val_loss: 0.6407 - val_accuracy: 0.8486\n",
            "Epoch 13/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.8390 - accuracy: 0.7459 - val_loss: 0.5972 - val_accuracy: 0.8566\n",
            "Epoch 14/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.8044 - accuracy: 0.7557 - val_loss: 0.5626 - val_accuracy: 0.8620\n",
            "Epoch 15/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.7659 - accuracy: 0.7656 - val_loss: 0.5333 - val_accuracy: 0.8657\n",
            "Epoch 16/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.7336 - accuracy: 0.7755 - val_loss: 0.5078 - val_accuracy: 0.8712\n",
            "Epoch 17/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.7097 - accuracy: 0.7815 - val_loss: 0.4862 - val_accuracy: 0.8754\n",
            "Epoch 18/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.6881 - accuracy: 0.7886 - val_loss: 0.4680 - val_accuracy: 0.8797\n",
            "Epoch 19/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.6657 - accuracy: 0.7949 - val_loss: 0.4518 - val_accuracy: 0.8818\n",
            "Epoch 20/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.6448 - accuracy: 0.8026 - val_loss: 0.4370 - val_accuracy: 0.8840\n",
            "Epoch 21/1000\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.6334 - accuracy: 0.8045 - val_loss: 0.4242 - val_accuracy: 0.8872\n",
            "Epoch 22/1000\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.6152 - accuracy: 0.8104 - val_loss: 0.4128 - val_accuracy: 0.8891\n",
            "Epoch 23/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.6032 - accuracy: 0.8146 - val_loss: 0.4026 - val_accuracy: 0.8917\n",
            "Epoch 24/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.5911 - accuracy: 0.8186 - val_loss: 0.3929 - val_accuracy: 0.8930\n",
            "Epoch 25/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.5812 - accuracy: 0.8233 - val_loss: 0.3845 - val_accuracy: 0.8944\n",
            "Epoch 26/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.5688 - accuracy: 0.8244 - val_loss: 0.3764 - val_accuracy: 0.8964\n",
            "Epoch 27/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.5582 - accuracy: 0.8292 - val_loss: 0.3690 - val_accuracy: 0.8978\n",
            "Epoch 28/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.5460 - accuracy: 0.8324 - val_loss: 0.3616 - val_accuracy: 0.8992\n",
            "Epoch 29/1000\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.5419 - accuracy: 0.8320 - val_loss: 0.3555 - val_accuracy: 0.9002\n",
            "Epoch 30/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.5314 - accuracy: 0.8376 - val_loss: 0.3498 - val_accuracy: 0.9008\n",
            "Epoch 31/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.5271 - accuracy: 0.8374 - val_loss: 0.3441 - val_accuracy: 0.9026\n",
            "Epoch 32/1000\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.5192 - accuracy: 0.8405 - val_loss: 0.3387 - val_accuracy: 0.9042\n",
            "Epoch 33/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.5137 - accuracy: 0.8440 - val_loss: 0.3337 - val_accuracy: 0.9051\n",
            "Epoch 34/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.5070 - accuracy: 0.8447 - val_loss: 0.3291 - val_accuracy: 0.9061\n",
            "Epoch 35/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4977 - accuracy: 0.8474 - val_loss: 0.3244 - val_accuracy: 0.9076\n",
            "Epoch 36/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4955 - accuracy: 0.8489 - val_loss: 0.3201 - val_accuracy: 0.9091\n",
            "Epoch 37/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4876 - accuracy: 0.8506 - val_loss: 0.3160 - val_accuracy: 0.9102\n",
            "Epoch 38/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4859 - accuracy: 0.8521 - val_loss: 0.3120 - val_accuracy: 0.9117\n",
            "Epoch 39/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4763 - accuracy: 0.8547 - val_loss: 0.3086 - val_accuracy: 0.9125\n",
            "Epoch 40/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4711 - accuracy: 0.8562 - val_loss: 0.3048 - val_accuracy: 0.9134\n",
            "Epoch 41/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4677 - accuracy: 0.8583 - val_loss: 0.3012 - val_accuracy: 0.9141\n",
            "Epoch 42/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4669 - accuracy: 0.8583 - val_loss: 0.2982 - val_accuracy: 0.9142\n",
            "Epoch 43/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4636 - accuracy: 0.8589 - val_loss: 0.2954 - val_accuracy: 0.9154\n",
            "Epoch 44/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4536 - accuracy: 0.8615 - val_loss: 0.2918 - val_accuracy: 0.9168\n",
            "Epoch 45/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4527 - accuracy: 0.8626 - val_loss: 0.2889 - val_accuracy: 0.9170\n",
            "Epoch 46/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4444 - accuracy: 0.8655 - val_loss: 0.2862 - val_accuracy: 0.9173\n",
            "Epoch 47/1000\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 0.4396 - accuracy: 0.8676 - val_loss: 0.2834 - val_accuracy: 0.9182\n",
            "Epoch 48/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4361 - accuracy: 0.8674 - val_loss: 0.2808 - val_accuracy: 0.9189\n",
            "Epoch 49/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4347 - accuracy: 0.8671 - val_loss: 0.2781 - val_accuracy: 0.9200\n",
            "Epoch 50/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4312 - accuracy: 0.8703 - val_loss: 0.2756 - val_accuracy: 0.9206\n",
            "Epoch 51/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4322 - accuracy: 0.8694 - val_loss: 0.2732 - val_accuracy: 0.9212\n",
            "Epoch 52/1000\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4272 - accuracy: 0.8703 - val_loss: 0.2712 - val_accuracy: 0.9216\n",
            "Epoch 53/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4224 - accuracy: 0.8714 - val_loss: 0.2688 - val_accuracy: 0.9220\n",
            "Epoch 54/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4209 - accuracy: 0.8723 - val_loss: 0.2666 - val_accuracy: 0.9228\n",
            "Epoch 55/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.4141 - accuracy: 0.8754 - val_loss: 0.2643 - val_accuracy: 0.9234\n",
            "Epoch 56/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4109 - accuracy: 0.8752 - val_loss: 0.2621 - val_accuracy: 0.9244\n",
            "Epoch 57/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4131 - accuracy: 0.8751 - val_loss: 0.2604 - val_accuracy: 0.9248\n",
            "Epoch 58/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.4091 - accuracy: 0.8777 - val_loss: 0.2587 - val_accuracy: 0.9248\n",
            "Epoch 59/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.4060 - accuracy: 0.8770 - val_loss: 0.2564 - val_accuracy: 0.9255\n",
            "Epoch 60/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4015 - accuracy: 0.8780 - val_loss: 0.2547 - val_accuracy: 0.9260\n",
            "Epoch 61/1000\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.4018 - accuracy: 0.8782 - val_loss: 0.2526 - val_accuracy: 0.9272\n",
            "Epoch 62/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3982 - accuracy: 0.8803 - val_loss: 0.2512 - val_accuracy: 0.9267\n",
            "Epoch 63/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3970 - accuracy: 0.8805 - val_loss: 0.2493 - val_accuracy: 0.9273\n",
            "Epoch 64/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3913 - accuracy: 0.8819 - val_loss: 0.2475 - val_accuracy: 0.9275\n",
            "Epoch 65/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3907 - accuracy: 0.8803 - val_loss: 0.2462 - val_accuracy: 0.9275\n",
            "Epoch 66/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3880 - accuracy: 0.8843 - val_loss: 0.2440 - val_accuracy: 0.9291\n",
            "Epoch 67/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3882 - accuracy: 0.8833 - val_loss: 0.2427 - val_accuracy: 0.9295\n",
            "Epoch 68/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3823 - accuracy: 0.8850 - val_loss: 0.2409 - val_accuracy: 0.9297\n",
            "Epoch 69/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3829 - accuracy: 0.8851 - val_loss: 0.2396 - val_accuracy: 0.9303\n",
            "Epoch 70/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3782 - accuracy: 0.8874 - val_loss: 0.2379 - val_accuracy: 0.9301\n",
            "Epoch 71/1000\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3752 - accuracy: 0.8872 - val_loss: 0.2362 - val_accuracy: 0.9309\n",
            "Epoch 72/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3770 - accuracy: 0.8877 - val_loss: 0.2352 - val_accuracy: 0.9315\n",
            "Epoch 73/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3749 - accuracy: 0.8878 - val_loss: 0.2337 - val_accuracy: 0.9323\n",
            "Epoch 74/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3696 - accuracy: 0.8888 - val_loss: 0.2323 - val_accuracy: 0.9325\n",
            "Epoch 75/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3683 - accuracy: 0.8888 - val_loss: 0.2306 - val_accuracy: 0.9330\n",
            "Epoch 76/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3676 - accuracy: 0.8900 - val_loss: 0.2292 - val_accuracy: 0.9333\n",
            "Epoch 77/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3635 - accuracy: 0.8907 - val_loss: 0.2281 - val_accuracy: 0.9337\n",
            "Epoch 78/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3648 - accuracy: 0.8915 - val_loss: 0.2266 - val_accuracy: 0.9341\n",
            "Epoch 79/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3631 - accuracy: 0.8897 - val_loss: 0.2256 - val_accuracy: 0.9339\n",
            "Epoch 80/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3622 - accuracy: 0.8906 - val_loss: 0.2245 - val_accuracy: 0.9344\n",
            "Epoch 81/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3576 - accuracy: 0.8913 - val_loss: 0.2231 - val_accuracy: 0.9351\n",
            "Epoch 82/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3566 - accuracy: 0.8934 - val_loss: 0.2220 - val_accuracy: 0.9355\n",
            "Epoch 83/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3543 - accuracy: 0.8928 - val_loss: 0.2207 - val_accuracy: 0.9355\n",
            "Epoch 84/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3526 - accuracy: 0.8941 - val_loss: 0.2193 - val_accuracy: 0.9359\n",
            "Epoch 85/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3526 - accuracy: 0.8938 - val_loss: 0.2185 - val_accuracy: 0.9359\n",
            "Epoch 86/1000\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.3527 - accuracy: 0.8931 - val_loss: 0.2176 - val_accuracy: 0.9363\n",
            "Epoch 87/1000\n",
            "60000/60000 [==============================] - 9s 145us/sample - loss: 0.3489 - accuracy: 0.8954 - val_loss: 0.2165 - val_accuracy: 0.9368\n",
            "Epoch 88/1000\n",
            "60000/60000 [==============================] - 9s 143us/sample - loss: 0.3508 - accuracy: 0.8950 - val_loss: 0.2153 - val_accuracy: 0.9369\n",
            "Epoch 89/1000\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.3476 - accuracy: 0.8956 - val_loss: 0.2144 - val_accuracy: 0.9366\n",
            "Epoch 90/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3451 - accuracy: 0.8973 - val_loss: 0.2131 - val_accuracy: 0.9372\n",
            "Epoch 91/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3440 - accuracy: 0.8979 - val_loss: 0.2119 - val_accuracy: 0.9372\n",
            "Epoch 92/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3387 - accuracy: 0.8971 - val_loss: 0.2108 - val_accuracy: 0.9378\n",
            "Epoch 93/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3386 - accuracy: 0.8992 - val_loss: 0.2095 - val_accuracy: 0.9382\n",
            "Epoch 94/1000\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3397 - accuracy: 0.8988 - val_loss: 0.2089 - val_accuracy: 0.9385\n",
            "Epoch 95/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3356 - accuracy: 0.8997 - val_loss: 0.2077 - val_accuracy: 0.9386\n",
            "Epoch 96/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3375 - accuracy: 0.8988 - val_loss: 0.2068 - val_accuracy: 0.9388\n",
            "Epoch 97/1000\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3360 - accuracy: 0.9002 - val_loss: 0.2059 - val_accuracy: 0.9390\n",
            "Epoch 98/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3344 - accuracy: 0.9002 - val_loss: 0.2049 - val_accuracy: 0.9397\n",
            "Epoch 99/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3322 - accuracy: 0.9021 - val_loss: 0.2038 - val_accuracy: 0.9398\n",
            "Epoch 100/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3301 - accuracy: 0.9029 - val_loss: 0.2030 - val_accuracy: 0.9402\n",
            "Epoch 101/1000\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.3316 - accuracy: 0.9013 - val_loss: 0.2018 - val_accuracy: 0.9408\n",
            "Epoch 102/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3257 - accuracy: 0.9031 - val_loss: 0.2010 - val_accuracy: 0.9411\n",
            "Epoch 103/1000\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3251 - accuracy: 0.9025 - val_loss: 0.2001 - val_accuracy: 0.9410\n",
            "Epoch 104/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3241 - accuracy: 0.9020 - val_loss: 0.1991 - val_accuracy: 0.9414\n",
            "Epoch 105/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3262 - accuracy: 0.9042 - val_loss: 0.1985 - val_accuracy: 0.9413\n",
            "Epoch 106/1000\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3252 - accuracy: 0.9030 - val_loss: 0.1977 - val_accuracy: 0.9414\n",
            "Epoch 107/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3209 - accuracy: 0.9040 - val_loss: 0.1967 - val_accuracy: 0.9417\n",
            "Epoch 108/1000\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3205 - accuracy: 0.9045 - val_loss: 0.1957 - val_accuracy: 0.9418\n",
            "Epoch 109/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3194 - accuracy: 0.9053 - val_loss: 0.1949 - val_accuracy: 0.9419\n",
            "Epoch 110/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3194 - accuracy: 0.9046 - val_loss: 0.1940 - val_accuracy: 0.9418\n",
            "Epoch 111/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3149 - accuracy: 0.9066 - val_loss: 0.1932 - val_accuracy: 0.9425\n",
            "Epoch 112/1000\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3117 - accuracy: 0.9074 - val_loss: 0.1925 - val_accuracy: 0.9426\n",
            "Epoch 113/1000\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3141 - accuracy: 0.9046 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 114/1000\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3148 - accuracy: 0.9058 - val_loss: 0.1909 - val_accuracy: 0.9438\n",
            "Epoch 115/1000\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3137 - accuracy: 0.9064 - val_loss: 0.1899 - val_accuracy: 0.9433\n",
            "Epoch 116/1000\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3099 - accuracy: 0.9083 - val_loss: 0.1890 - val_accuracy: 0.9435\n",
            "Epoch 117/1000\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3111 - accuracy: 0.9063 - val_loss: 0.1881 - val_accuracy: 0.9445\n",
            "Epoch 118/1000\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.3090 - accuracy: 0.9074 - val_loss: 0.1874 - val_accuracy: 0.9440\n",
            "Epoch 119/1000\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.3097 - accuracy: 0.9083 - val_loss: 0.1868 - val_accuracy: 0.9450\n",
            "Epoch 120/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3037 - accuracy: 0.9093 - val_loss: 0.1861 - val_accuracy: 0.9451\n",
            "Epoch 121/1000\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.3077 - accuracy: 0.9077 - val_loss: 0.1854 - val_accuracy: 0.9453\n",
            "Epoch 122/1000\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3031 - accuracy: 0.9091 - val_loss: 0.1843 - val_accuracy: 0.9453\n",
            "Epoch 123/1000\n",
            " 9344/60000 [===>..........................] - ETA: 6s - loss: 0.3048 - accuracy: 0.9074"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-63ae1b6a6a73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#エポック数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#訓練の進行度合いを表示\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     validation_data=(x_test, y_test)) #テスト\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUfld3EsJBlX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "8aa4e7c6-6d15-4bd9-e7c6-061de54064b0"
      },
      "source": [
        "#訓練時の精度と損失の描画\n",
        "#フォントの制御\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.patheffects as path_effects\n",
        "\n",
        "\n",
        "#精度グラフの描画\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.plot(history['acc'],\n",
        "         color='b',\n",
        "         linestyle='-',\n",
        "         linewidth=3,\n",
        "         path_effects=[path_effects.SimpleLineShadow(),\n",
        "                       path_effects.Normal()])\n",
        "plt.plot(history.history['val_acc'],\n",
        "         color='r',\n",
        "         linestyle='--',\n",
        "         linewidth=3,\n",
        "         path_effects=[path_effects.SimpleLineShadow(),\n",
        "                       path_effects.Normal()])\n",
        "plt.tick_params(labelsize=18)\n",
        "\n",
        "plt.title('エポック-精度グラフ(MNIST_CNN)',fontsize=30,font_properties=fp2)\n",
        "plt.ylabel('制度')\n",
        "plt.xlabel('エポック')\n",
        "plt.legend(['訓練','テスト'], loc='best', fontsize=25, prop=fp2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-7000f31b49d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#精度グラフの描画\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m plt.plot(history['acc'],\n\u001b[0m\u001b[1;32m      9\u001b[0m          \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m          \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sHsDC7aNHGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}